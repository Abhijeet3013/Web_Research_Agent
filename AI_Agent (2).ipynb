{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8Sjp_IbFePI",
        "outputId": "d6756978-c30b-43f8-e45a-c43961d86848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.75.0)\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.11/dist-packages (2.4.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4 requests openai google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import time\n",
        "import os\n",
        "from typing import List, Dict, Optional\n",
        "from dataclasses import dataclass\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from requests.exceptions import RequestException\n",
        "from serpapi import GoogleSearch\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Configure API keys (set these as environment variables)\n",
        "SERPAPI_KEY = os.getenv(\"9bbc3a0bfb66807580039d323417a5c25e97146f5825a6adf2429c4005d4011f\")\n",
        "GEMINI_KEY = os.getenv(\"AIzaSyDqVQMoxKe7ztiAdZncf7yQ11u6tDAjd-w\")\n",
        "\n",
        "# Initialize Gemini\n",
        "genai.configure(api_key=GEMINI_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "@dataclass\n",
        "class SearchResult:\n",
        "    url: str\n",
        "    title: str\n",
        "    snippet: str\n",
        "    source: str\n",
        "\n",
        "@dataclass\n",
        "class ScrapedContent:\n",
        "    url: str\n",
        "    title: str\n",
        "    text: str\n",
        "    authors: List[str]\n",
        "    publish_date: Optional[str]\n",
        "    main_content: str\n",
        "\n",
        "@dataclass\n",
        "class ResearchReport:\n",
        "    query: str\n",
        "    summary: str\n",
        "    sources: List[Dict]\n",
        "    key_points: List[str]\n",
        "    answer: str\n",
        "\n",
        "class SerpAPISearchTool:\n",
        "    \"\"\"Real search using SerpAPI\"\"\"\n",
        "\n",
        "    def search(self, query: str, num_results: int = 5) -> List[SearchResult]:\n",
        "        params = {\n",
        "            \"q\": query,\n",
        "            \"api_key\": SERPAPI_KEY,\n",
        "            \"num\": num_results\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            search = GoogleSearch(params)\n",
        "            results = search.get_dict()\n",
        "            search_results = []\n",
        "            if \"organic_results\" in results:\n",
        "                for result in results[\"organic_results\"]:\n",
        "                    search_results.append(SearchResult(\n",
        "                        url=result.get(\"link\", \"\"),\n",
        "                        title=result.get(\"title\", \"\"),\n",
        "                        snippet=result.get(\"snippet\", \"\"),\n",
        "                        source=result.get(\"source\", \"\")\n",
        "                    ))\n",
        "            return search_results[:num_results]\n",
        "        except Exception as e:\n",
        "            print(f\"Search error: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "class WebScraper:\n",
        "    \"\"\"Handles web page scraping with respect to robots.txt\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "\n",
        "    def scrape(self, url: str) -> Optional[ScrapedContent]:\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            title = soup.title.string if soup.title else \"No title found\"\n",
        "            paragraphs = soup.find_all('p')\n",
        "            text = ' '.join([p.get_text() for p in paragraphs])\n",
        "\n",
        "            authors = []\n",
        "            publish_date = None\n",
        "            for meta in soup.find_all(\"meta\"):\n",
        "                if \"name\" in meta.attrs:\n",
        "                    if \"author\" in meta.attrs[\"name\"].lower():\n",
        "                        authors.append(meta.attrs.get(\"content\", \"\"))\n",
        "                    elif \"date\" in meta.attrs[\"name\"].lower():\n",
        "                        publish_date = meta.attrs.get(\"content\", None)\n",
        "\n",
        "            return ScrapedContent(\n",
        "                url=url,\n",
        "                title=title,\n",
        "                text=text,\n",
        "                authors=authors,\n",
        "                publish_date=publish_date,\n",
        "                main_content=text[:2000]\n",
        "            )\n",
        "        except RequestException as e:\n",
        "            print(f\"Error scraping {url}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "class GeminiContentAnalyzer:\n",
        "    \"\"\"Uses Gemini for advanced content analysis and summarization\"\"\"\n",
        "\n",
        "    def analyze_relevance(self, content: ScrapedContent, query: str) -> float:\n",
        "        prompt = f\"\"\"\n",
        "        Rate the relevance of this content to the query on a scale from 0 to 1.\n",
        "        Query: {query}\n",
        "        Content Title: {content.title}\n",
        "        Content Snippet: {content.main_content[:500]}\n",
        "\n",
        "        Return ONLY a number between 0 and 1 with 2 decimal places.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            return float(response.text.strip())\n",
        "        except Exception as e:\n",
        "            print(f\"Gemini error: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "    def summarize(self, contents: List[ScrapedContent], query: str) -> ResearchReport:\n",
        "        sources_text = \"\\n\\n\".join([\n",
        "            f\"Source {i+1}:\\nURL: {c.url}\\nTitle: {c.title}\\nContent: {c.main_content[:1000]}\"\n",
        "            for i, c in enumerate(contents)\n",
        "        ])\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        You are a professional research assistant. Create a detailed report answering:\n",
        "        Query: {query}\n",
        "\n",
        "        Using these sources:\n",
        "        {sources_text}\n",
        "\n",
        "        Your report must include:\n",
        "        1. A comprehensive summary answering the query\n",
        "        2. 3-5 key points extracted from the sources\n",
        "        3. A list of all sources used\n",
        "\n",
        "        Return your response in JSON format with these keys:\n",
        "        - \"summary\": The complete summary\n",
        "        - \"key_points\": List of key points\n",
        "        - \"answer\": Concise direct answer\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            result = json.loads(response.text)\n",
        "            return ResearchReport(\n",
        "                query=query,\n",
        "                summary=result[\"summary\"],\n",
        "                sources=[{\"url\": c.url, \"title\": c.title} for c in contents],\n",
        "                key_points=result[\"key_points\"],\n",
        "                answer=result[\"answer\"]\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Gemini summarization error: {str(e)}\")\n",
        "            return ResearchReport(\n",
        "                query=query,\n",
        "                summary=\"Error generating report\",\n",
        "                sources=[],\n",
        "                key_points=[],\n",
        "                answer=\"Error generating answer\"\n",
        "            )\n",
        "\n",
        "class WebResearchAgent:\n",
        "    \"\"\"Main research agent with Gemini integration\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.search_tool = SerpAPISearchTool()\n",
        "        self.scraper = WebScraper()\n",
        "        self.analyzer = GeminiContentAnalyzer()\n",
        "        self.visited_urls = set()\n",
        "\n",
        "    def research(self, query: str, max_sources: int = 3) -> ResearchReport:\n",
        "        print(f\"Starting research for: {query}\")\n",
        "\n",
        "        # Perform web search\n",
        "        search_results = self.search_tool.search(query)\n",
        "        print(f\"Found {len(search_results)} search results\")\n",
        "\n",
        "        # Scrape top results\n",
        "        scraped_contents = []\n",
        "        for result in search_results[:max_sources]:\n",
        "            if result.url not in self.visited_urls:\n",
        "                print(f\"Scraping: {result.url}\")\n",
        "                content = self.scraper.scrape(result.url)\n",
        "                if content:\n",
        "                    scraped_contents.append(content)\n",
        "                    self.visited_urls.add(result.url)\n",
        "\n",
        "        # Analyze and filter content\n",
        "        scored_contents = []\n",
        "        for content in scraped_contents:\n",
        "            score = self.analyzer.analyze_relevance(content, query)\n",
        "            print(f\"Relevance score for {content.url}: {score:.2f}\")\n",
        "            if score > 0.5:\n",
        "                scored_contents.append((score, content))\n",
        "\n",
        "        # Sort by relevance and generate report\n",
        "        scored_contents.sort(reverse=True, key=lambda x: x[0])\n",
        "        relevant_contents = [c for (s, c) in scored_contents]\n",
        "\n",
        "        if not relevant_contents:\n",
        "            return ResearchReport(\n",
        "                query=query,\n",
        "                summary=\"No relevant information found\",\n",
        "                sources=[],\n",
        "                key_points=[],\n",
        "                answer=\"No information found for this query\"\n",
        "            )\n",
        "\n",
        "        return self.analyzer.summarize(relevant_contents, query)"
      ],
      "metadata": {
        "id": "2x5t9tiwICNN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from web_research_agent import WebResearchAgent\n",
        "\n",
        "# Create an instance of the agent\n",
        "agent = WebResearchAgent()\n",
        "\n",
        "# Test with different queries\n",
        "queries = [\n",
        "    \"What is the latest news about AI advancements in 2024?\",\n",
        "    \"Explain quantum computing in simple terms\",\n",
        "    \"Compare React and Vue.js for frontend development\"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"Researching: {query}\")\n",
        "    report = agent.research(query)\n",
        "\n",
        "    print(\"\\nResearch Report:\")\n",
        "    print(f\"Query: {report.query}\")\n",
        "    print(\"\\nSummary:\")\n",
        "    print(report.summary)\n",
        "    print(\"\\nKey Points:\")\n",
        "    for point in report.key_points:\n",
        "        print(f\"- {point}\")\n",
        "    print(\"\\nSources:\")\n",
        "    for source in report.sources:\n",
        "        print(f\"- {source['title']}: {source['url']}\")\n",
        "    print(\"\\nDirect Answer:\")\n",
        "    print(report.answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBqsRu1zGhEJ",
        "outputId": "c988cfdb-86ca-416f-8af0-aa0d4a492d7f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Researching: What is the latest news about AI advancements in 2024?\n",
            "Starting research for: What is the latest news about AI advancements in 2024?\n",
            "Found 4 search results\n",
            "Scraping: https://www.artificialintelligence-news.com/\n",
            "Error scraping https://www.artificialintelligence-news.com/: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
            "Scraping: https://blog.google/technology/ai/2024-ai-extraordinary-progress-advancement/\n",
            "Scraping: https://iot-analytics.com/ai-2024-10-most-notable-stories/\n",
            "Query appears news-oriented, checking news sources\n",
            "OpenAI error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Relevance score for https://blog.google/technology/ai/2024-ai-extraordinary-progress-advancement/: 0.00\n",
            "OpenAI error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Relevance score for https://iot-analytics.com/ai-2024-10-most-notable-stories/: 0.00\n",
            "OpenAI error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Relevance score for https://www.techtarget.com/searchenterpriseai/tip/9-top-AI-and-machine-learning-trends: 0.00\n",
            "OpenAI error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Relevance score for https://www.crn.com/news/ai/2024/the-10-biggest-ai-news-stories-of-2024-nvidia-genai-and-cybersecurity: 0.00\n",
            "\n",
            "Research Report:\n",
            "Query: What is the latest news about AI advancements in 2024?\n",
            "\n",
            "Summary:\n",
            "No relevant information found\n",
            "\n",
            "Key Points:\n",
            "\n",
            "Sources:\n",
            "\n",
            "Direct Answer:\n",
            "No information found for this query\n",
            "\n",
            "================================================================================\n",
            "Researching: Explain quantum computing in simple terms\n",
            "Starting research for: Explain quantum computing in simple terms\n",
            "Found 3 search results\n",
            "Scraping: https://aws.amazon.com/what-is/quantum-computing/\n",
            "Scraping: https://www.investopedia.com/terms/q/quantum-computing.asp\n",
            "Scraping: https://www.reddit.com/r/QuantumComputing/comments/yjnvwh/explain_it_like_im_5/\n",
            "Error scraping https://www.reddit.com/r/QuantumComputing/comments/yjnvwh/explain_it_like_im_5/: 403 Client Error: Blocked for url: https://www.reddit.com/r/QuantumComputing/comments/yjnvwh/explain_it_like_im_5/\n",
            "OpenAI error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Relevance score for https://aws.amazon.com/what-is/quantum-computing/: 0.00\n",
            "OpenAI error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Relevance score for https://www.investopedia.com/terms/q/quantum-computing.asp: 0.00\n",
            "\n",
            "Research Report:\n",
            "Query: Explain quantum computing in simple terms\n",
            "\n",
            "Summary:\n",
            "No relevant information found\n",
            "\n",
            "Key Points:\n",
            "\n",
            "Sources:\n",
            "\n",
            "Direct Answer:\n",
            "No information found for this query\n",
            "\n",
            "================================================================================\n",
            "Researching: Compare React and Vue.js for frontend development\n",
            "Starting research for: Compare React and Vue.js for frontend development\n",
            "Found 3 search results\n",
            "Scraping: https://radixweb.com/blog/react-vs-vue\n",
            "Scraping: https://www.mindinventory.com/blog/reactjs-vs-vuejs/\n",
            "Scraping: https://www.reddit.com/r/reactjs/comments/10u17c7/what_does_react_do_better_than_vue_innately/\n",
            "Error scraping https://www.reddit.com/r/reactjs/comments/10u17c7/what_does_react_do_better_than_vue_innately/: 403 Client Error: Blocked for url: https://www.reddit.com/r/reactjs/comments/10u17c7/what_does_react_do_better_than_vue_innately/\n",
            "OpenAI error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Relevance score for https://radixweb.com/blog/react-vs-vue: 0.00\n",
            "OpenAI error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Relevance score for https://www.mindinventory.com/blog/reactjs-vs-vuejs/: 0.00\n",
            "\n",
            "Research Report:\n",
            "Query: Compare React and Vue.js for frontend development\n",
            "\n",
            "Summary:\n",
            "No relevant information found\n",
            "\n",
            "Key Points:\n",
            "\n",
            "Sources:\n",
            "\n",
            "Direct Answer:\n",
            "No information found for this query\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from web_research_agent import WebResearchAgent\n",
        "agent = WebResearchAgent()\n",
        "report = agent.research(\"What are the latest advancements in AI?\")\n",
        "print(report.summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dd0-HmcIGfi",
        "outputId": "500a975a-8a00-43cf-b8fd-8adda00cb887"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting research for: What are the latest advancements in AI?\n",
            "Found 4 search results\n",
            "Scraping: https://www.koombea.com/blog/7-recent-ai-developments/\n",
            "Scraping: https://online-engineering.case.edu/blog/advancements-in-artificial-intelligence-and-machine-learning\n",
            "Scraping: https://www.sciencedaily.com/news/computers_math/artificial_intelligence/\n",
            "Query appears news-oriented, checking news sources\n",
            "OpenAI error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Relevance score for https://www.koombea.com/blog/7-recent-ai-developments/: 0.00\n",
            "OpenAI error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Relevance score for https://online-engineering.case.edu/blog/advancements-in-artificial-intelligence-and-machine-learning: 0.00\n",
            "OpenAI error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Relevance score for https://www.sciencedaily.com/news/computers_math/artificial_intelligence/: 0.00\n",
            "OpenAI error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Relevance score for https://appinventiv.com/blog/ai-trends/: 0.00\n",
            "OpenAI error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Relevance score for https://www.forbes.com/councils/forbestechcouncil/2025/03/05/clarifying-the-latest-ai-advancements/: 0.00\n",
            "OpenAI error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Relevance score for https://blog.google/technology/ai/2024-ai-extraordinary-progress-advancement/: 0.00\n",
            "No relevant information found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "from web_research_agent import WebResearchAgent\n",
        "import os\n",
        "\n",
        "agent = WebResearchAgent()\n",
        "\n",
        "def research(query):\n",
        "    report = agent.research(query)\n",
        "    return f\"\"\"\n",
        "# {report.query}\n",
        "## Summary\n",
        "{report.summary}\n",
        "\n",
        "## Key Points\n",
        "- \"\"\" + \"\\n- \".join(report.key_points) + f\"\"\"\n",
        "\n",
        "## Sources\n",
        "- \"\"\" + \"\\n- \".join([f\"{s['title']}: {s['url']}\" for s in report.sources])\n",
        "\n",
        "gr.Interface(\n",
        "    fn=research,\n",
        "    inputs=gr.Textbox(label=\"Enter your research query\"),\n",
        "    outputs=gr.Markdown(),\n",
        "    title=\"Web Research Agent (Gemini)\",\n",
        "    description=\"AI research assistant using SerpAPI and Google Gemini\"\n",
        ").launch()"
      ],
      "metadata": {
        "id": "znI1Ej4cSy2Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7800b53-a570-427d-a704-17e458a9939a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.26.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.9.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.9.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e71ba4a44ad28af42a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e71ba4a44ad28af42a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rmQrgh4K__zS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}